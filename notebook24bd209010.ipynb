{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":63056,"databundleVersionId":9094797,"sourceType":"competition"},{"sourceId":9219508,"sourceType":"datasetVersion","datasetId":5575412},{"sourceId":88865810,"sourceType":"kernelVersion"},{"sourceId":82227,"sourceType":"modelInstanceVersion","modelInstanceId":69085,"modelId":94212},{"sourceId":82335,"sourceType":"modelInstanceVersion","modelInstanceId":69085,"modelId":94212},{"sourceId":103851,"sourceType":"modelInstanceVersion","modelInstanceId":87054,"modelId":111293}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Als je een zip-bestand hebt geüpload, eerst uitpakken\n# !unzip -q /kaggle/input/pytorch-metric-learning.zip -d /kaggle/working/\n\n# Installeer de whl-bestanden\n# !pip install /kaggle/input/pytorch-metric-learning\n# !pip install pytorch_metric_learning --no-index --find-links=file:///kaggle/input/pytorch-metric-learning\n!pip install pytorch_metric_learning","metadata":{"execution":{"iopub.status.busy":"2024-09-04T11:52:22.862048Z","iopub.execute_input":"2024-09-04T11:52:22.862852Z","iopub.status.idle":"2024-09-04T11:52:37.288596Z","shell.execute_reply.started":"2024-09-04T11:52:22.862818Z","shell.execute_reply":"2024-09-04T11:52:37.287330Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting pytorch_metric_learning\n  Downloading pytorch_metric_learning-2.6.0-py3-none-any.whl.metadata (17 kB)\nRequirement already satisfied: numpy<2.0 in /opt/conda/lib/python3.10/site-packages (from pytorch_metric_learning) (1.26.4)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from pytorch_metric_learning) (1.2.2)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from pytorch_metric_learning) (2.1.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from pytorch_metric_learning) (4.66.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->pytorch_metric_learning) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->pytorch_metric_learning) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->pytorch_metric_learning) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->pytorch_metric_learning) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->pytorch_metric_learning) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->pytorch_metric_learning) (2024.3.1)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pytorch_metric_learning) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pytorch_metric_learning) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pytorch_metric_learning) (3.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->pytorch_metric_learning) (2.1.3)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->pytorch_metric_learning) (1.3.0)\nDownloading pytorch_metric_learning-2.6.0-py3-none-any.whl (119 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.3/119.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: pytorch_metric_learning\nSuccessfully installed pytorch_metric_learning-2.6.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport h5py\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom PIL import Image\nfrom io import BytesIO\nfrom tqdm import tqdm\nimport torch\nfrom torch.cuda.amp import autocast, GradScaler\nfrom pytorch_metric_learning import losses, miners\nfrom pytorch_metric_learning.utils.accuracy_calculator import AccuracyCalculator\nfrom pytorch_metric_learning.distances import LpDistance\nfrom pytorch_metric_learning.miners import PairMarginMiner, TripletMarginMiner\nfrom torch import nn, optim\nfrom torchvision import transforms","metadata":{"execution":{"iopub.status.busy":"2024-09-04T11:52:37.290616Z","iopub.execute_input":"2024-09-04T11:52:37.290918Z","iopub.status.idle":"2024-09-04T11:52:43.399062Z","shell.execute_reply.started":"2024-09-04T11:52:37.290890Z","shell.execute_reply":"2024-09-04T11:52:43.398076Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Load data","metadata":{}},{"cell_type":"code","source":"\"\"\"2024 ISIC Challenge primary prize scoring metric\n\nGiven a list of binary labels, an associated list of prediction \nscores ranging from [0,1], this function produces, as a single value, \nthe partial area under the receiver operating characteristic (pAUC) \nabove a given true positive rate (TPR).\nhttps://en.wikipedia.org/wiki/Partial_Area_Under_the_ROC_Curve.\n\n(c) 2024 Nicholas R Kurtansky, MSKCC\n\"\"\"\n\n\nclass ParticipantVisibleError(Exception):\n    pass\n\n\ndef score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str, min_tpr: float=0.80) -> float:\n    '''\n    2024 ISIC Challenge metric: pAUC\n    \n    Given a solution file and submission file, this function returns the\n    the partial area under the receiver operating characteristic (pAUC) \n    above a given true positive rate (TPR) = 0.80.\n    https://en.wikipedia.org/wiki/Partial_Area_Under_the_ROC_Curve.\n    \n    (c) 2024 Nicholas R Kurtansky, MSKCC\n\n    Args:\n        solution: ground truth pd.DataFrame of 1s and 0s\n        submission: solution dataframe of predictions of scores ranging [0, 1]\n\n    Returns:\n        Float value range [0, max_fpr]\n    '''\n\n    del solution[row_id_column_name]\n    del submission[row_id_column_name]\n\n    # check submission is numeric\n    if not pd.api.types.is_numeric_dtype(submission.values):\n        raise ParticipantVisibleError('Submission target column must be numeric')\n\n    # rescale the target. set 0s to 1s and 1s to 0s (since sklearn only has max_fpr)\n    v_gt = abs(np.asarray(solution.values)-1)\n    \n    # flip the submissions to their compliments\n    v_pred = -1.0*np.asarray(submission.values)\n\n    max_fpr = abs(1-min_tpr)\n\n    # using sklearn.metric functions: (1) roc_curve and (2) auc\n    fpr, tpr, _ = roc_curve(v_gt, v_pred, sample_weight=None)\n    if max_fpr is None or max_fpr == 1:\n        return auc(fpr, tpr)\n    if max_fpr <= 0 or max_fpr > 1:\n        raise ValueError(\"Expected min_tpr in range [0, 1), got: %r\" % min_tpr)\n        \n    # Add a single point at max_fpr by linear interpolation\n    stop = np.searchsorted(fpr, max_fpr, \"right\")\n    x_interp = [fpr[stop - 1], fpr[stop]]\n    y_interp = [tpr[stop - 1], tpr[stop]]\n    tpr = np.append(tpr[:stop], np.interp(max_fpr, x_interp, y_interp))\n    fpr = np.append(fpr[:stop], max_fpr)\n    partial_auc = auc(fpr, tpr)\n\n    #     # Equivalent code that uses sklearn's roc_auc_score\n    #     v_gt = abs(np.asarray(solution.values)-1)\n    #     v_pred = np.array([1.0 - x for x in submission.values])\n    #     max_fpr = abs(1-min_tpr)\n    #     partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n    #     # change scale from [0.5, 1.0] to [0.5 * max_fpr**2, max_fpr]\n    #     # https://math.stackexchange.com/questions/914823/shift-numbers-into-a-different-range\n    #     partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n    \n    return(partial_auc)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T11:52:43.400385Z","iopub.execute_input":"2024-09-04T11:52:43.401197Z","iopub.status.idle":"2024-09-04T11:52:43.412938Z","shell.execute_reply.started":"2024-09-04T11:52:43.401168Z","shell.execute_reply":"2024-09-04T11:52:43.411914Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# # Load data\ndata_path = '/kaggle/input/isic-2024-challenge/'\npath_train_hdf5 = os.path.join(data_path, 'train-image.hdf5')\npath_test_hdf5 = os.path.join(data_path, 'test-image.hdf5')\n\npath_train_meta = data_path + 'train-metadata.csv'\npath_test_meta = data_path + 'test-metadata.csv'\n\nimport pandas as pd\n\n# Bestaande data\ndata_path = '/kaggle/input/isic-2024-challenge/'\npath_train_hdf5 = os.path.join(data_path, 'train-image.hdf5')\ntrain_hdf5 = h5py.File(path_train_hdf5, 'r')\ntrain_meta = pd.read_csv(os.path.join(data_path, 'train-metadata.csv'))\n\n\nextra_dir_1 = '/kaggle/input/old-data/archive(4)/train-image/image/'\nextra_meta_1 = pd.read_csv('/kaggle/input/old-data/archive(4)/train-metadata.csv')\n\nextra_dir_2 = '/kaggle/input/old-data/archive(2)/train-image/image/'\nextra_meta_2 = pd.read_csv('/kaggle/input/old-data/archive(5)/train-metadata.csv')\n\nextra_dir_3 = '/kaggle/input/old-data/archive(3)/train-image/image/'\nextra_meta_3 = pd.read_csv('/kaggle/input/old-data/archive(3)/train-metadata.csv')\n\n# Combineer metadata (verondersteld dat image_id de kolomnaam is)\ncombined_meta = pd.concat([train_meta, extra_meta_1, extra_meta_2, extra_meta_3], ignore_index=True)\njpeg_dirs = [extra_dir_1, extra_dir_2, extra_dir_3]\n","metadata":{"execution":{"iopub.status.busy":"2024-09-04T11:52:43.415455Z","iopub.execute_input":"2024-09-04T11:52:43.415882Z","iopub.status.idle":"2024-09-04T11:52:50.483782Z","shell.execute_reply.started":"2024-09-04T11:52:43.415849Z","shell.execute_reply":"2024-09-04T11:52:50.482778Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/386316080.py:15: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n  train_meta = pd.read_csv(os.path.join(data_path, 'train-metadata.csv'))\n","output_type":"stream"}]},{"cell_type":"code","source":"train_hdf5 = h5py.File(path_train_hdf5, 'r')\ntest_hdf5 = h5py.File(path_test_hdf5, 'r')","metadata":{"execution":{"iopub.status.busy":"2024-09-04T11:52:50.485008Z","iopub.execute_input":"2024-09-04T11:52:50.485324Z","iopub.status.idle":"2024-09-04T11:52:50.492919Z","shell.execute_reply.started":"2024-09-04T11:52:50.485298Z","shell.execute_reply":"2024-09-04T11:52:50.492059Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_meta = pd.read_csv(path_train_meta)\ntrain_meta = train_meta.ffill()\ntest_meta = pd.read_csv(path_test_meta)\ntest_meta = test_meta.ffill()","metadata":{"execution":{"iopub.status.busy":"2024-09-04T11:52:50.494137Z","iopub.execute_input":"2024-09-04T11:52:50.494412Z","iopub.status.idle":"2024-09-04T11:52:57.328994Z","shell.execute_reply.started":"2024-09-04T11:52:50.494390Z","shell.execute_reply":"2024-09-04T11:52:57.327962Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/1751422235.py:1: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n  train_meta = pd.read_csv(path_train_meta)\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\n\n# Assuming train_meta is your metadata DataFrame\ncategorical_columns = [\"sex\", \"anatom_site_general\", \"tbp_tile_type\", \"tbp_lv_location\"]\nnumerical_columns = [\n    \"age_approx\", \"tbp_lv_nevi_confidence\", \"clin_size_long_diam_mm\",\n    \"tbp_lv_areaMM2\", \"tbp_lv_area_perim_ratio\", \"tbp_lv_color_std_mean\", \n    \"tbp_lv_deltaLBnorm\", \"tbp_lv_minorAxisMM\"\n]\n\n# Define the transformation pipeline for both numerical and categorical features\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', StandardScaler(), numerical_columns),\n        ('cat', OneHotEncoder(), categorical_columns)\n    ]\n)\n\n# Fit the preprocessor on the training data\npreprocessor.fit(train_meta)\n\n# Apply the preprocessing to the metadata\nprocessed_meta = preprocessor.transform(train_meta)\nprocessed_meta = pd.DataFrame(processed_meta)  # Convert back to DataFrame for better handling\n","metadata":{"execution":{"iopub.status.busy":"2024-09-04T11:52:57.330367Z","iopub.execute_input":"2024-09-04T11:52:57.330765Z","iopub.status.idle":"2024-09-04T11:52:58.761611Z","shell.execute_reply.started":"2024-09-04T11:52:57.330726Z","shell.execute_reply":"2024-09-04T11:52:58.760592Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# read in the isic ids and target values\ntrain_isic_ids = train_meta['isic_id'].values\ntrain_isic_ids = train_meta[train_meta['lesion_id'].notnull()]['isic_id'].values\n\ntest_isic_ids = test_meta['isic_id'].values\n\ntrain_targets = train_meta[train_meta['lesion_id'].notnull()]['target'].values","metadata":{"execution":{"iopub.status.busy":"2024-09-04T11:52:58.762926Z","iopub.execute_input":"2024-09-04T11:52:58.763291Z","iopub.status.idle":"2024-09-04T11:52:59.108193Z","shell.execute_reply.started":"2024-09-04T11:52:58.763260Z","shell.execute_reply":"2024-09-04T11:52:59.107173Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"total_size = len(train_targets)\nindices = np.arange(total_size)\n\ntrain_size = int(total_size * 0.8)\nval_size = total_size - train_size\n\ntrain_indices, val_indices = train_test_split(indices, test_size=val_size, train_size=train_size)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-04T11:52:59.109430Z","iopub.execute_input":"2024-09-04T11:52:59.109783Z","iopub.status.idle":"2024-09-04T11:52:59.129613Z","shell.execute_reply.started":"2024-09-04T11:52:59.109750Z","shell.execute_reply":"2024-09-04T11:52:59.128621Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"num_samples = len(train_isic_ids)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T11:52:59.132965Z","iopub.execute_input":"2024-09-04T11:52:59.133291Z","iopub.status.idle":"2024-09-04T11:52:59.137952Z","shell.execute_reply.started":"2024-09-04T11:52:59.133265Z","shell.execute_reply":"2024-09-04T11:52:59.137089Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom torch.utils.data import WeightedRandomSampler\n\n# Veronderstel dat je al de targets hebt (bijv. train_targets of labels)\nclass_counts = np.bincount(train_targets)  # Aantal samples per klasse\nclass_weights = 1. / class_counts  # Omgekeerde van het aantal samples per klasse\nsample_weights = class_weights[train_targets]  # Gewichten per sample gebaseerd op hun klasse\n\n# Maak een WeightedRandomSampler met deze sample gewichten\nsampler = WeightedRandomSampler(weights=sample_weights, num_samples=num_samples, replacement=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-04T11:52:59.139090Z","iopub.execute_input":"2024-09-04T11:52:59.139416Z","iopub.status.idle":"2024-09-04T11:52:59.159152Z","shell.execute_reply.started":"2024-09-04T11:52:59.139391Z","shell.execute_reply":"2024-09-04T11:52:59.158420Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Pytorch gedeelte","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nimport numpy as np\nfrom io import BytesIO\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\n\nclass TripletISICDataset(Dataset):\n    def __init__(self, hdf5_file=None, isic_ids=None, targets=None, jpeg_dirs=None, meta_data=None, feature_extractor=None, transform=None):\n        self.hdf5_file = hdf5_file\n        self.isic_ids = isic_ids\n        self.targets = targets\n        self.jpeg_dirs = jpeg_dirs if jpeg_dirs is not None else []\n        self.meta_data = meta_data\n        self.feature_extractor = feature_extractor\n        self.transform = transform\n        \n        # Label encoders and scalers for preprocessing metadata\n        self.label_encoders = {}\n        self.scalers = {}\n        self._prepare_metadata_encoders()\n\n    def _prepare_metadata_encoders(self):\n        # Identificeer categorische en numerieke kolommen\n        categorical_columns = ['sex', 'anatom_site_general', 'tbp_tile_type', 'tbp_lv_location']\n        numerical_columns = ['age_approx', 'tbp_lv_nevi_confidence', 'clin_size_long_diam_mm',\n                             'tbp_lv_areaMM2', 'tbp_lv_area_perim_ratio', 'tbp_lv_color_std_mean',\n                             'tbp_lv_deltaLBnorm', 'tbp_lv_minorAxisMM']\n\n        # Prepareer label encoders voor categorische kolommen\n        for col in categorical_columns:\n            le = LabelEncoder()\n            self.meta_data.loc[:, col] = le.fit_transform(self.meta_data[col].astype(str))\n            self.label_encoders[col] = le\n\n        # Prepareer scalers voor numerieke kolommen\n        for col in numerical_columns:\n            scaler = StandardScaler()\n            self.meta_data.loc[:, col] = scaler.fit_transform(self.meta_data[col].values.reshape(-1, 1))\n            self.scalers[col] = scaler\n    def __len__(self):\n        return len(self.isic_ids)\n\n    def __getitem__(self, idx):\n        isic_id = str(self.isic_ids[idx])\n\n        # Load anchor image\n        anchor_image, anchor_label = self._load_image_and_label(idx)\n\n        # Get positive and negative ids based on implemented logic\n        positive_idx = self._get_positive_id(idx, anchor_label)\n        negative_idx = self._get_negative_id(idx, anchor_label)\n\n        # Load positive and negative images\n        positive_image, _ = self._load_image_and_label(positive_idx)\n        negative_image, _ = self._load_image_and_label(negative_idx)\n\n        # Load metadata\n        anchor_meta = self._load_metadata(idx)\n        positive_meta = self._load_metadata(positive_idx)\n        negative_meta = self._load_metadata(negative_idx)\n\n        return (anchor_image, positive_image, negative_image), (anchor_meta, positive_meta, negative_meta), anchor_label\n\n    def _load_metadata(self, idx):\n        isic_id = str(self.isic_ids[idx])\n        meta = self.meta_data[self.meta_data['isic_id'] == isic_id].drop(columns=['isic_id']).values.flatten().astype(np.float32)\n        return torch.tensor(meta)\n\n    def _load_image_and_label(self, idx):\n        isic_id = str(self.isic_ids[idx])\n        image = None\n\n        for jpeg_dir in self.jpeg_dirs:\n            image_path = os.path.join(jpeg_dir, f\"{isic_id}.jpeg\")\n            if os.path.exists(image_path):\n                image = Image.open(image_path)\n                break\n\n        if image is None and self.hdf5_file:\n            image = Image.open(BytesIO(self.hdf5_file[isic_id][()]))\n\n        if image is None:\n            raise FileNotFoundError(f\"Afbeelding {isic_id} niet gevonden.\")\n\n        # Converteer de afbeelding naar RGB indien nodig\n        if isinstance(image, np.ndarray):\n            image = Image.fromarray(image)\n\n        image = image.convert(\"RGB\")\n\n        # Toepassen van de transformaties\n        if self.feature_extractor:\n            image = self.feature_extractor(image)  # Zorg ervoor dat de extractor geen keyword 'images=' vereist\n        elif self.transform:\n            image = self.transform(image)\n        else:\n            image = torch.tensor(np.array(image)).permute(2, 0, 1).float() / 255.0\n\n        label = self.targets[idx]\n        return image, label\n\n    def _get_positive_id(self, idx, anchor_label):\n        positive_indices = np.where(self.targets == anchor_label)[0]\n        positive_indices = positive_indices[positive_indices != idx]  # Vermijd dezelfde index\n        if len(positive_indices) == 0:\n            raise ValueError(\"Geen positieve sample gevonden\")\n        return np.random.choice(positive_indices)\n\n    def _get_negative_id(self, idx, anchor_label):\n        negative_indices = np.where(self.targets != anchor_label)[0]\n        if len(negative_indices) == 0:\n            raise ValueError(\"Geen negatieve sample gevonden\")\n        return np.random.choice(negative_indices)\n\n    def to_pytorch_loader(self, batch_size=32, shuffle=True, num_workers=4, sampler=None):\n        if sampler:\n            return DataLoader(self, batch_size=batch_size, sampler=sampler, num_workers=num_workers)\n        else:\n            return DataLoader(self, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n\n    @staticmethod\n    def collate_fn(batch):\n        (anchor_images, positive_images, negative_images), (anchor_metadata, positive_metadata, negative_metadata), labels = zip(*batch)\n        anchor_images = torch.stack(anchor_images)\n        positive_images = torch.stack(positive_images)\n        negative_images = torch.stack(negative_images)\n        anchor_metadata = torch.stack(anchor_metadata)\n        positive_metadata = torch.stack(positive_metadata)\n        negative_metadata = torch.stack(negative_metadata)\n        labels = torch.tensor(labels)\n        return (anchor_images, positive_images, negative_images), (anchor_metadata, positive_metadata, negative_metadata), labels\n","metadata":{"execution":{"iopub.status.busy":"2024-09-04T11:52:59.160357Z","iopub.execute_input":"2024-09-04T11:52:59.160620Z","iopub.status.idle":"2024-09-04T11:52:59.187068Z","shell.execute_reply.started":"2024-09-04T11:52:59.160598Z","shell.execute_reply":"2024-09-04T11:52:59.186094Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class SingleImageISICDataset(Dataset):\n    def __init__(self, hdf5_file=None, isic_ids=None, targets=None, jpeg_dirs=None, meta_data=None, transform=None):\n        self.hdf5_file = hdf5_file\n        self.isic_ids = isic_ids\n        self.targets = targets\n        self.jpeg_dirs = jpeg_dirs if jpeg_dirs is not None else []\n        self.meta_data = meta_data  # Processed metadata\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.isic_ids)\n\n    def __getitem__(self, idx):\n        isic_id = str(self.isic_ids[idx])\n\n        # Load the image\n        image = self._load_image(isic_id)\n\n        # Apply image transformations\n        if self.transform:\n            image = self.transform(image)\n\n        # Get the metadata for this sample\n        metadata = torch.tensor(self.meta_data.iloc[idx].values).float()\n\n        # Get the target label\n        label = self.targets[idx]\n\n        return (image, metadata), label\n\n    def _load_image(self, isic_id):\n        image = None\n\n        for jpeg_dir in self.jpeg_dirs:\n            image_path = os.path.join(jpeg_dir, f\"{isic_id}.jpeg\")\n            if os.path.exists(image_path):\n                image = Image.open(image_path)\n                break\n\n        if image is None and self.hdf5_file:\n            image = Image.open(BytesIO(self.hdf5_file[isic_id][()]))\n\n        if image is None:\n            raise FileNotFoundError(f\"Image {isic_id} not found.\")\n\n        image = image.convert(\"RGB\")\n        return image\n\n    def to_pytorch_loader(self, batch_size=32, shuffle=True, num_workers=4):\n        return DataLoader(self, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-04T11:52:59.188286Z","iopub.execute_input":"2024-09-04T11:52:59.188577Z","iopub.status.idle":"2024-09-04T11:52:59.201370Z","shell.execute_reply.started":"2024-09-04T11:52:59.188542Z","shell.execute_reply":"2024-09-04T11:52:59.200487Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torchvision import models, transforms\n\n# Laad het ResNet-50 model\n# model = models.resnet50(pretrained=True)  # Zet pretrained=False omdat je eigen gewichten laadt\n# Pad naar de opgeslagen gewichten\n# weights_path = \"/kaggle/input/resnet/pytorch/default/1/resnet50-0676ba61.pth\"\n\n# Laad de gewichten\n# model.load_state_dict(torch.load(weights_path, map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu')))\n\n\n# Laad het ResNet-50 model en vervang de laatste volledig verbonden laag\n# model.fc = nn.Linear(model.fc.in_features, 128)  # Pas de output aan naar 128 dimensies\n\n\n# # Voor training met triplet loss, kan het helpen om de output te normaliseren\n# class ResNet50TripletModel(nn.Module):\n#     def __init__(self, backbone):\n#         super(ResNet50TripletModel, self).__init__()\n#         self.backbone = backbone\n\n#     def forward(self, x):\n#         # Gebruik de backbone voor feature extractie\n#         x = self.backbone(x)\n#         # Normaliseer de embeddings\n#         x = nn.functional.normalize(x, p=2, dim=1)\n#         return x\n\n# # Maak een instance van het aangepaste ResNet50 model\n# triplet_model = ResNet50TripletModel(model)\n\n# Definieer de image transforms (feature extractor voor ResNet-50)\n# Stel de image transforms in voor ResNet-50\nfeature_extractor = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\ntransform = transforms.Compose([\n    transforms.CenterCrop(200),  # Crop naar 200x200 pixels centraal gebied\n    transforms.Resize((128, 128)),  # Optioneel: Resize naar 128x128\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Verplaats het model naar het juiste device\n# triplet_model = triplet_model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T11:52:59.202595Z","iopub.execute_input":"2024-09-04T11:52:59.202935Z","iopub.status.idle":"2024-09-04T11:52:59.213479Z","shell.execute_reply.started":"2024-09-04T11:52:59.202906Z","shell.execute_reply":"2024-09-04T11:52:59.212590Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-04T11:52:59.214261Z","iopub.execute_input":"2024-09-04T11:52:59.214500Z","iopub.status.idle":"2024-09-04T11:52:59.254736Z","shell.execute_reply.started":"2024-09-04T11:52:59.214479Z","shell.execute_reply":"2024-09-04T11:52:59.253765Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"class COMTripletLoss(nn.Module):\n    def __init__(self):\n        super(COMTripletLoss, self).__init__()\n\n    def forward(self, anchor, positive, negative):\n        # Bepaal het centrum van de positieve klasse als het gemiddelde van de anker en positieve embeddings\n        center = (anchor + positive) / 2\n        \n        # Bereken de afstand van anchor en positive tot het centrum\n        pos_dist = (anchor - center).pow(2).sum(1) + (positive - center).pow(2).sum(1)\n        \n        # Bereken de afstand van negative tot het centrum\n        neg_dist = (negative - center).pow(2).sum(1)\n        \n        # De loss is de som van de positieve afstanden min de negatieve afstand\n        loss = pos_dist - neg_dist\n        \n        # Loss moet altijd positief zijn, daarom nemen we de gemiddelde waarde en nemen we de maximale waarde tussen loss en 0.\n        return loss.clamp(min=0).mean()","metadata":{"execution":{"iopub.status.busy":"2024-09-04T11:52:59.256019Z","iopub.execute_input":"2024-09-04T11:52:59.256381Z","iopub.status.idle":"2024-09-04T11:52:59.264298Z","shell.execute_reply.started":"2024-09-04T11:52:59.256349Z","shell.execute_reply":"2024-09-04T11:52:59.263389Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"class TrainingCallback:\n    def on_epoch_end(self, epoch, model, optimizer, loss, metrics=None):\n        pass\nclass ModelCheckpointCallback(TrainingCallback):\n    def __init__(self, save_path=\"model_checkpoint.pth\"):\n        self.save_path = save_path\n\n    def on_epoch_end(self, epoch, model, optimizer, loss, metrics=None):\n        torch.save({\n            'epoch': epoch,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'loss': loss,\n        }, self.save_path)\n        print(f\"Model opgeslagen na epoch {epoch} met verlies: {loss:.4f}\")\n\nclass EarlyStoppingCallback(TrainingCallback):\n    def __init__(self, patience=5, min_delta=0):\n        self.patience = patience\n        self.min_delta = min_delta\n        self.best_loss = None\n        self.counter = 0\n\n    def on_epoch_end(self, epoch, model, optimizer, loss, metrics=None):\n        if self.best_loss is None or loss < self.best_loss - self.min_delta:\n            self.best_loss = loss\n            self.counter = 0\n        else:\n            self.counter += 1\n            if self.counter >= self.patience:\n                print(f\"Early stopping geactiveerd na {epoch + 1} epochs.\")\n                return True\n        return False","metadata":{"execution":{"iopub.status.busy":"2024-09-04T11:52:59.265315Z","iopub.execute_input":"2024-09-04T11:52:59.265593Z","iopub.status.idle":"2024-09-04T11:52:59.276330Z","shell.execute_reply.started":"2024-09-04T11:52:59.265563Z","shell.execute_reply":"2024-09-04T11:52:59.275387Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import models\n\nclass MultimodalEfficientNet(nn.Module):\n    def __init__(self, metadata_feature_size):\n        super(MultimodalEfficientNet, self).__init__()\n        \n        # Load the EfficientNet-B0 model\n        self.cnn_model = models.efficientnet_b0(pretrained=True)\n        \n        # Get the number of features from the classifier layer\n        cnn_output_features = self.cnn_model.classifier[1].in_features\n        self.cnn_model.classifier = nn.Identity()  # Remove the original classifier\n\n        # Define a fully connected layer for the metadata\n        self.metadata_fc = nn.Sequential(\n            nn.Linear(metadata_feature_size, 128),\n            nn.ReLU(),\n            nn.Linear(128, 64),\n            nn.ReLU()\n        )\n        \n        # Combine the image and metadata features\n        self.fc = nn.Linear(cnn_output_features + 64, 1)  # Binary classification\n\n    def forward(self, images, metadata):\n        # Process the image data through the EfficientNet backbone\n        image_features = self.cnn_model(images)\n        \n        # Process the metadata\n        metadata_features = self.metadata_fc(metadata)\n        \n        # Combine the image and metadata features\n        combined_features = torch.cat((image_features, metadata_features), dim=1)\n        \n        # Apply a final fully connected layer\n        output = self.fc(combined_features)\n        \n        return output\n","metadata":{"execution":{"iopub.status.busy":"2024-09-04T11:52:59.277533Z","iopub.execute_input":"2024-09-04T11:52:59.277878Z","iopub.status.idle":"2024-09-04T11:52:59.288140Z","shell.execute_reply.started":"2024-09-04T11:52:59.277845Z","shell.execute_reply":"2024-09-04T11:52:59.287357Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Categorical features which will be one hot encoded\nCATEGORICAL_COLUMNS = [\"sex\", \"anatom_site_general\",\n            \"tbp_tile_type\",\"tbp_lv_location\", \"isic_id\" ]\n\n# Numeraical features which will be normalized\nNUMERIC_COLUMNS = [\"age_approx\", \"tbp_lv_nevi_confidence\", \"clin_size_long_diam_mm\",\n           \"tbp_lv_areaMM2\", \"tbp_lv_area_perim_ratio\", \"tbp_lv_color_std_mean\",\n           \"tbp_lv_deltaLBnorm\", \"tbp_lv_minorAxisMM\", ]\n\n# Tabular feature columns\nFEAT_COLS = CATEGORICAL_COLUMNS + NUMERIC_COLUMNS","metadata":{"execution":{"iopub.status.busy":"2024-09-04T11:52:59.289394Z","iopub.execute_input":"2024-09-04T11:52:59.289873Z","iopub.status.idle":"2024-09-04T11:52:59.298562Z","shell.execute_reply.started":"2024-09-04T11:52:59.289840Z","shell.execute_reply":"2024-09-04T11:52:59.297850Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"metadata_feature_size = len(NUMERIC_COLUMNS)  # Je moet een variabele hebben die de numerieke kolommen telt\nnum_categorical_features = 4  # Je moet een variabele hebben die de categorische kolommen telt\n# Initialiseer het model met de juiste parameters\nprint(f\"Expected metadata size: {metadata_feature_size + num_categorical_features}\")\nprint(f\"Actual metadata size: {train_meta[FEAT_COLS].shape[1]}\")\n\n# Dit zorgt ervoor dat de invoergrootte overeenkomt met wat de laag verwacht.\n\nmodel = MultimodalEfficientNet(\n    metadata_feature_size=metadata_feature_size,\n).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T11:56:05.535890Z","iopub.execute_input":"2024-09-04T11:56:05.536264Z","iopub.status.idle":"2024-09-04T11:56:06.102806Z","shell.execute_reply.started":"2024-09-04T11:56:05.536235Z","shell.execute_reply":"2024-09-04T11:56:06.102058Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Expected metadata size: 12\nActual metadata size: 13\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n100%|██████████| 20.5M/20.5M [00:00<00:00, 85.8MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import models\nfrom torch.optim import Adam\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom tqdm import tqdm\n\ndef train_bce_pauc_model(model, dataloader, num_epochs=20, optimizer=None, scheduler=None, callbacks=None, save_path=\"model_weights.pth\"):\n    model.train()\n    for epoch in range(num_epochs):\n        epoch_loss = 0.0\n        progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\")\n\n        for batch in progress_bar:\n            optimizer.zero_grad()\n\n            # Unpack the images, metadata, and labels\n            (images, metadata), labels = batch\n\n            # Send to device\n            images = images.to(device)\n            metadata = metadata.to(device)\n            labels = labels.to(device).float()\n\n            labels = labels.to(device).unsqueeze(1)  # Reshape labels to [batch_size, 1]\n\n            # Compute the output\n            output = model(images, metadata).to(device)\n\n            # Compute the loss\n            loss = nn.BCEWithLogitsLoss()(output, labels)\n\n            # Backward pass and optimization\n            loss.backward()\n            optimizer.step()\n\n            epoch_loss += loss.item()\n            progress_bar.set_postfix({\"loss\": loss.item()})\n\n        # Scheduler step (if applicable)\n        if scheduler is not None:\n            scheduler.step(epoch_loss)\n\n        # Execute callbacks\n        if callbacks:\n            for callback in callbacks:\n                should_stop = callback.on_epoch_end(epoch, model, optimizer, epoch_loss)\n                if should_stop:\n                    print(\"Training stopped by callback.\")\n                    return\n\n        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss / len(dataloader):.4f}')\n\n    if save_path:\n        torch.save(model.state_dict(), save_path)\n        print(f\"Model weights saved to {save_path}\")\n\n# Setting up the weighted BCE loss to handle class imbalance\nclass_weights = torch.tensor([0.7, 0.3])  # Example weights: adjust based on class distribution\ncriterion = nn.BCEWithLogitsLoss(pos_weight=class_weights.to(device))\n\n# Model initialization\n# model = MultimodalEfficientNet(\n#     metadata_feature_size=metadata_feature_size,\n#     num_categorical_features=CATEGORICAL_COLUMNS\n# ).to(device)\n\noptimizer = Adam(model.parameters(), lr=1e-3)\nscheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, verbose=True)\n\n# Example callbacks\ncallbacks = [\n    ModelCheckpointCallback(save_path=\"best_model.pth\"),\n    EarlyStoppingCallback(patience=3, min_delta=0.01)\n]\n\n# Create the dataset\ndataset = SingleImageISICDataset(\n    hdf5_file=train_hdf5,\n    isic_ids=train_meta['isic_id'].values,\n    targets=train_meta['target'].values,\n    jpeg_dirs=jpeg_dirs,\n    meta_data=processed_meta,  # Pass the processed metadata\n    transform=transform\n)\n\n# Create the DataLoader\ntrain_dataloader = dataset.to_pytorch_loader(batch_size=32, shuffle=True, num_workers=4)\n\n# Example of how the data is loaded\nfor (images, metadata), labels in train_dataloader:\n    print(\"Images shape:\", images.shape)\n    print(\"Metadata shape:\", metadata.shape) \n    print(\"Labels shape:\", labels.shape)\n    break\n    \n# Initialize the model\nmetadata_feature_size = processed_meta.shape[1]  # This corresponds to 71 after processing\nmodel = MultimodalEfficientNet(metadata_feature_size).to(device)\n\n# Define your optimizer, loss function, and other components\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\ncriterion = nn.BCEWithLogitsLoss()\n\n# Train the model\ntrain_bce_pauc_model(\n    model,\n    train_dataloader,\n    num_epochs=20,\n    optimizer=optimizer,\n    scheduler=scheduler,\n    callbacks=callbacks\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T11:57:31.202788Z","iopub.execute_input":"2024-09-04T11:57:31.203202Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Images shape: torch.Size([32, 3, 128, 128])\nMetadata shape: torch.Size([32, 38])\nLabels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/20: 100%|██████████| 12534/12534 [13:57<00:00, 14.96batch/s, loss=0.000286]\n","output_type":"stream"},{"name":"stdout","text":"Model opgeslagen na epoch 0 met verlies: 114.7897\nEpoch [1/20], Loss: 0.0092\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/20: 100%|██████████| 12534/12534 [13:40<00:00, 15.28batch/s, loss=0.00149] \n","output_type":"stream"},{"name":"stdout","text":"Model opgeslagen na epoch 1 met verlies: 74.7114\nEpoch [2/20], Loss: 0.0060\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/20: 100%|██████████| 12534/12534 [13:37<00:00, 15.33batch/s, loss=0.000306]\n","output_type":"stream"},{"name":"stdout","text":"Model opgeslagen na epoch 2 met verlies: 67.6507\nEpoch [3/20], Loss: 0.0054\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/20:  81%|████████  | 10161/12534 [11:03<02:44, 14.44batch/s, loss=0.00149] ","output_type":"stream"}]},{"cell_type":"markdown","source":"moi!","metadata":{}},{"cell_type":"code","source":"optimizer = optim.AdamW(model.parameters(), lr=1e-5)\n# Loss functie en miner voor semi-hard negatieve mijnbouw\n# loss_func = losses.TripletMarginLoss(margin=0.2)\n\n# Loss functie en miner voor semi-hard negatieve mijnbouw\nloss_func = COMTripletLoss()\n\nminer = TripletMarginMiner(margin=0.05, type_of_triplets=\"semihard\")\n\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nscheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True, min_lr=1e-7)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T10:55:29.865798Z","iopub.status.idle":"2024-09-04T10:55:29.866389Z","shell.execute_reply.started":"2024-09-04T10:55:29.866150Z","shell.execute_reply":"2024-09-04T10:55:29.866174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Maak een instance van de COM-Triplet Loss\ncom_triplet_loss = COMTripletLoss()\n\ndef train_com_triplet_model(model, dataloader, num_epochs=10, optimizer=None, loss_func=None, miner=None, scheduler=None, callbacks=None, save_path=\"model_weights.pth\"):\n    model.train()\n    for epoch in range(num_epochs):\n        epoch_loss = 0.0\n        progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\")\n\n        for batch in progress_bar:\n            optimizer.zero_grad()\n\n            # Unpack the triplets\n            (anchor_images, positive_images, negative_images), (anchor_metadata, positive_metadata, negative_metadata), labels = batch\n\n            # Send to device\n            anchor_images = anchor_images.to(device)\n            positive_images = positive_images.to(device)\n            negative_images = negative_images.to(device)\n            anchor_metadata = anchor_metadata.to(device)\n            positive_metadata = positive_metadata.to(device)\n            negative_metadata = negative_metadata.to(device)\n\n            # Compute embeddings\n            anchor_embedding = model(anchor_images, anchor_metadata).to(device)\n            positive_embedding = model(positive_images, positive_metadata).to(device)\n            negative_embedding = model(negative_images, negative_metadata).to(device)\n              # Check for NaN in embeddings\n            if torch.isnan(anchor_embedding).any() or torch.isnan(positive_embedding).any() or torch.isnan(negative_embedding).any():\n#                 print(\"Found NaN in embeddings, skipping this batch\")\n                continue\n\n            embeddings = torch.cat([anchor_embedding, positive_embedding, negative_embedding], dim=0)\n            labels = torch.cat([labels, labels, labels])\n\n            # Mine hard negatives\n            hard_pairs = miner(embeddings, labels)\n\n            # Check if hard_pairs are empty\n            if any(t.numel() == 0 for t in hard_pairs):\n                # Use a fallback loss calculation when no hard pairs are found\n                loss = loss_func(anchor_embedding, positive_embedding, negative_embedding)\n            else:\n                # Extract the indices for hard pairs\n                anchor_idx, positive_idx, negative_idx = hard_pairs[:3]\n\n                # Select only the hard pairs\n                hard_anchor = embeddings[anchor_idx]\n                hard_positive = embeddings[positive_idx]\n                hard_negative = embeddings[negative_idx]\n\n                # Compute loss with only hard pairs\n                loss = loss_func(hard_anchor, hard_positive, hard_negative)\n\n            loss.backward()\n            optimizer.step()\n\n            epoch_loss += loss.item()\n            progress_bar.set_postfix({\"loss\": loss.item()})\n#             del anchor_images, positive_images, negative_images, anchor_metadata, positive_metadata, negative_metadata, anchor_embedding, positive_embedding, negative_embedding\n            \n        # Scheduler step (if applicable)\n        if scheduler is not None:\n            scheduler.step(epoch_loss)\n\n        # Voer callbacks uit\n        if callbacks:\n            for callback in callbacks:\n                should_stop = callback.on_epoch_end(epoch, model, optimizer, epoch_loss)\n                if should_stop:\n                    print(\"Training gestopt door callback.\")\n                    return\n\n        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss / len(dataloader):.4f}')\n\n    if save_path:\n        torch.save(model.state_dict(), save_path)\n        print(f\"Model gewichten opgeslagen in {save_path}\")\n\n# Creëer de dataset\ntriplet_dataset = TripletISICDataset(\n    hdf5_file=train_hdf5,\n    isic_ids=train_meta['isic_id'].values,\n    targets=train_meta['target'].values,\n    jpeg_dirs=jpeg_dirs,\n    meta_data=train_meta[FEAT_COLS],  # De volledige metadata dataframe, inclusief numerieke en categorische kolommen\n    feature_extractor=None,\n    transform = transform\n)\n\n# Creëer de DataLoader\ntrain_dataloader = triplet_dataset.to_pytorch_loader(batch_size=32, shuffle=True, num_workers=4)\n\n# Een batch uit de DataLoader halen om te controleren\nfor (anchor_images, positive_images, negative_images), (anchor_metadata, positive_metadata, negative_metadata), labels in train_dataloader:\n    print(\"Anchor images shape:\", anchor_images.shape)\n    print(\"Anchor metadata shape:\", anchor_metadata.shape)\n    print(\"Labels shape:\", labels.shape)\n    break\n# Start het training proces\n# train_com_triplet_model(model, train_dataloader, num_epochs=1, optimizer=optimizer, loss_func=loss_func, miner=miner, scheduler=scheduler, sampler=sampler)\n\ncallbacks = [\n    ModelCheckpointCallback(save_path=\"best_model.pth\"),\n    EarlyStoppingCallback(patience=3, min_delta=0.01)\n]\n\n\ntrain_com_triplet_model(\n    model,\n    train_dataloader,\n    num_epochs=20,\n    optimizer=optimizer,\n    loss_func=com_triplet_loss,\n    miner=miner,\n    scheduler=scheduler,\n    callbacks=callbacks\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T10:55:29.869410Z","iopub.status.idle":"2024-09-04T10:55:29.870738Z","shell.execute_reply.started":"2024-09-04T10:55:29.870325Z","shell.execute_reply":"2024-09-04T10:55:29.870377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision.models as models\n\n# Laad het ResNet-50 model\nmodel = models.resnet50(pretrained=False)\n\n# Pas de laatste volledig verbonden laag aan voor het aantal outputfeatures (bijvoorbeeld 128)\n# Dit is belangrijk voor triplet loss waarbij de outputdimensie moet passen\nmodel.fc = nn.Linear(in_features=model.fc.in_features, out_features=128)\n\n# Laad de getrainde gewichten\nmodel.load_state_dict(torch.load(\"/kaggle/input/triplet_loss_resnet/pytorch/default/1/model_weights.pth\"))\nmodel.eval()  # Zet het model in evaluatiemodus","metadata":{"execution":{"iopub.status.busy":"2024-09-04T09:52:49.898759Z","iopub.status.idle":"2024-09-04T09:52:49.899182Z","shell.execute_reply.started":"2024-09-04T09:52:49.898956Z","shell.execute_reply":"2024-09-04T09:52:49.898972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def custom_collate_fn(batch):\n    images, ids = zip(*batch)  # Unzip de batch in images en ids\n    images = [img.unsqueeze(0) for img in images]  # Voeg een batch dim toe aan elke image\n    images = torch.cat(images, dim=0)  # Combineer alle images in één batch tensor\n    return images, ids","metadata":{"execution":{"iopub.status.busy":"2024-09-04T09:52:49.901303Z","iopub.status.idle":"2024-09-04T09:52:49.901739Z","shell.execute_reply.started":"2024-09-04T09:52:49.901520Z","shell.execute_reply":"2024-09-04T09:52:49.901538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torchvision.transforms as transforms\n\n# Definieer de transform om alle afbeeldingen naar 224x224 te schalen en naar tensor om te zetten\nimage_transform = transforms.Compose([\n    transforms.Resize((224, 224)),  # Schaal afbeeldingen naar 224x224 pixels\n    transforms.ToTensor(),          # Converteer naar een torch tensor\n])\n\n# Aangepaste datasetclass voor de testset\nclass TestISICDataset(Dataset):\n    def __init__(self, hdf5_file, isic_ids, transform=None):\n        self.hdf5_file = hdf5_file\n        self.isic_ids = isic_ids\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.isic_ids)\n\n    def __getitem__(self, idx):\n        isic_id = str(self.isic_ids[idx])\n        image = Image.open(BytesIO(self.hdf5_file[isic_id][()]))\n        image = image.convert(\"RGB\")\n        if self.transform:\n            image = self.transform(image)\n        else:\n            image = torch.tensor(np.array(image)).permute(2, 0, 1).float() / 255.0\n        return image, isic_id\n\n# Laad de testset in een DataLoader met de aangepaste collate_fn en transform\ntest_dataset = TestISICDataset(hdf5_file=test_hdf5, isic_ids=test_isic_ids, transform=image_transform)\ntest_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2, collate_fn=custom_collate_fn)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-04T09:52:49.903319Z","iopub.status.idle":"2024-09-04T09:52:49.903777Z","shell.execute_reply.started":"2024-09-04T09:52:49.903539Z","shell.execute_reply":"2024-09-04T09:52:49.903557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_embeddings(model, dataloader, device):\n    model.eval()\n    embeddings = []\n    ids = []\n\n    with torch.no_grad():\n        for batch in dataloader:\n            images, isic_ids = batch  # Zorg ervoor dat de batch correct opgesplitst wordt\n            \n            # Controleer of images een lijst is en stack alleen als dat nodig is\n            if isinstance(images, list):\n                images = torch.stack(images)  # Combineer de lijst van tensors tot één tensor\n            \n            images = images.to(device)  # Verplaats de tensor naar het apparaat\n            \n            # Bereken de embeddings met het model\n            embedding = model(images)\n            embeddings.append(embedding)\n            ids.extend(isic_ids)  # Voeg IDs toe aan de lijst\n    \n    embeddings = torch.cat(embeddings)  # Combineer alle embeddings tot één tensor\n    return embeddings, ids\n\n# Laad het getrainde model en zet het op het juiste device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Bereken embeddings voor de testset\ntest_embeddings, test_ids = compute_embeddings(model, test_dataloader, device)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-04T09:52:49.905268Z","iopub.status.idle":"2024-09-04T09:52:49.905684Z","shell.execute_reply.started":"2024-09-04T09:52:49.905478Z","shell.execute_reply":"2024-09-04T09:52:49.905495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Placeholder predictiefunctie\ndef predict_labels(embeddings):\n    # Dummy implementatie - vervang met je daadwerkelijke predictielogica\n    return torch.zeros(len(embeddings))  # Vervang dit met daadwerkelijke voorspellingen\n\n# Voer voorspellingen uit op de test embeddings\npredicted_labels = predict_labels(test_embeddings)\n\n# Maak de submissie aan in een pandas DataFrame\nsubmission_df = pd.DataFrame({\n    'isic_id': test_ids,\n    'predicted_label': predicted_labels.cpu().numpy()  # Converteer tensor naar numpy array\n})\n\n# Opslaan van de submissie\nsubmission_df.to_csv('submission.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-04T09:52:49.906958Z","iopub.status.idle":"2024-09-04T09:52:49.907505Z","shell.execute_reply.started":"2024-09-04T09:52:49.907229Z","shell.execute_reply":"2024-09-04T09:52:49.907252Z"},"trusted":true},"execution_count":null,"outputs":[]}]}