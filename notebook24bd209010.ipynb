{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":63056,"databundleVersionId":9094797,"sourceType":"competition"}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport h5py\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom transformers import TFViTModel, ViTFeatureExtractor\nfrom PIL import Image\nfrom io import BytesIO\nfrom sklearn.metrics import roc_curve, auc","metadata":{"execution":{"iopub.status.busy":"2024-07-18T12:51:11.117438Z","iopub.execute_input":"2024-07-18T12:51:11.117775Z","iopub.status.idle":"2024-07-18T12:51:11.125551Z","shell.execute_reply.started":"2024-07-18T12:51:11.117742Z","shell.execute_reply":"2024-07-18T12:51:11.124480Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"markdown","source":"# Load data","metadata":{}},{"cell_type":"code","source":"# Load data\n# define data path\ndata_path = '/kaggle/input/isic-2024-challenge/'\n\npath_train_hdf5 = os.path.join(data_path, 'train-image.hdf5')\npath_test_hdf5 = os.path.join(data_path, 'test-image.hdf5')\n\npath_train_meta = data_path + 'train-metadata.csv'\npath_test_meta = data_path + 'test-metadata.csv'","metadata":{"execution":{"iopub.status.busy":"2024-07-18T12:51:11.127139Z","iopub.execute_input":"2024-07-18T12:51:11.127496Z","iopub.status.idle":"2024-07-18T12:51:11.177780Z","shell.execute_reply.started":"2024-07-18T12:51:11.127462Z","shell.execute_reply":"2024-07-18T12:51:11.176850Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"# load data\ntrain_hdf5 = h5py.File(path_train_hdf5, 'r')\ntest_hdf5 = h5py.File(path_test_hdf5, 'r')","metadata":{"execution":{"iopub.status.busy":"2024-07-18T12:51:11.180192Z","iopub.execute_input":"2024-07-18T12:51:11.180491Z","iopub.status.idle":"2024-07-18T12:51:11.190982Z","shell.execute_reply.started":"2024-07-18T12:51:11.180453Z","shell.execute_reply":"2024-07-18T12:51:11.190007Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"# Load metadata\ntrain_meta = pd.read_csv(path_train_meta)\ntest_meta = pd.read_csv(path_test_meta)","metadata":{"execution":{"iopub.status.busy":"2024-07-18T12:51:11.192239Z","iopub.execute_input":"2024-07-18T12:51:11.192608Z","iopub.status.idle":"2024-07-18T12:51:18.445091Z","shell.execute_reply.started":"2024-07-18T12:51:11.192574Z","shell.execute_reply":"2024-07-18T12:51:18.444081Z"},"trusted":true},"execution_count":74,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/1940620682.py:2: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n  train_meta = pd.read_csv(path_train_meta)\n","output_type":"stream"}]},{"cell_type":"code","source":"# read in the isic ids and target values\ntrain_isic_ids = train_meta['isic_id'].values\ntrain_isic_ids = train_meta[train_meta['lesion_id'].notnull()]['isic_id'].values\n\ntest_isic_ids = test_meta['isic_id'].values\n\ntrain_targets = train_meta[train_meta['lesion_id'].notnull()]['target'].values","metadata":{"execution":{"iopub.status.busy":"2024-07-18T12:51:18.446363Z","iopub.execute_input":"2024-07-18T12:51:18.446656Z","iopub.status.idle":"2024-07-18T12:51:18.546099Z","shell.execute_reply.started":"2024-07-18T12:51:18.446631Z","shell.execute_reply":"2024-07-18T12:51:18.545341Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"len(train_targets)","metadata":{"execution":{"iopub.status.busy":"2024-07-18T12:51:18.547108Z","iopub.execute_input":"2024-07-18T12:51:18.547361Z","iopub.status.idle":"2024-07-18T12:51:18.553409Z","shell.execute_reply.started":"2024-07-18T12:51:18.547339Z","shell.execute_reply":"2024-07-18T12:51:18.552493Z"},"trusted":true},"execution_count":76,"outputs":[{"execution_count":76,"output_type":"execute_result","data":{"text/plain":"22058"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import train_test_split\n\n# Splits de data in train en validation sets\ntotal_size = len(train_targets)\nindices = np.arange(total_size)\n\n# Definieer de verhoudingen voor train en val\ntrain_size = int(total_size * 0.8)  # Pas dit aan naar jouw gewenste verhouding\nval_size = total_size - train_size\n\n# Gebruik train_test_split om indices te splitsen\ntrain_indices, val_indices = train_test_split(indices, test_size=val_size, train_size=train_size)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-18T12:51:18.554387Z","iopub.execute_input":"2024-07-18T12:51:18.554727Z","iopub.status.idle":"2024-07-18T12:51:18.564388Z","shell.execute_reply.started":"2024-07-18T12:51:18.554681Z","shell.execute_reply":"2024-07-18T12:51:18.563538Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"print(train_indices, val_indices)","metadata":{"execution":{"iopub.status.busy":"2024-07-18T12:51:18.565529Z","iopub.execute_input":"2024-07-18T12:51:18.565808Z","iopub.status.idle":"2024-07-18T12:51:18.573155Z","shell.execute_reply.started":"2024-07-18T12:51:18.565785Z","shell.execute_reply":"2024-07-18T12:51:18.572333Z"},"trusted":true},"execution_count":78,"outputs":[{"name":"stdout","text":"[ 7568  5943 12226 ...  2204 11342   236] [11494  1894 16083 ... 12221  9481 10866]\n","output_type":"stream"}]},{"cell_type":"code","source":"def preprocess_image(image):\n    image = tf.image.resize(image, [224, 224])\n    if image.shape[-1] == 1:  # Handle grayscale images\n        image = tf.image.grayscale_to_rgb(image)\n    print(image.shape[-1])\n    image = image[..., ::-1]\n    return image","metadata":{"execution":{"iopub.status.busy":"2024-07-18T12:51:18.576181Z","iopub.execute_input":"2024-07-18T12:51:18.576436Z","iopub.status.idle":"2024-07-18T12:51:18.583490Z","shell.execute_reply.started":"2024-07-18T12:51:18.576415Z","shell.execute_reply":"2024-07-18T12:51:18.582619Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"class ISICDataset(tf.keras.utils.Sequence):\n    def __init__(self, hdf5_file, isic_ids, targets=None, feature_extractor=None, batch_size=32):\n        self.hdf5_file = hdf5_file\n        self.isic_ids = isic_ids\n        self.targets = targets\n        self.feature_extractor = feature_extractor\n        self.batch_size = batch_size\n        \n    def __len__(self):\n        return len(self.isic_ids)\n    \n    def __getitem__(self, idx):\n        isic_id = str(self.isic_ids[idx])\n        image = Image.open(BytesIO(self.hdf5_file[isic_id][()]))\n        image = image.convert(\"RGB\")\n        image = np.array(image)\n        if self.feature_extractor:\n            image = self.feature_extractor(images=image, return_tensors=\"tf\").pixel_values[0]\n        if self.targets is not None:\n            target = self.targets[idx]\n            return image, target\n        else:\n            return image\n    \n    def _load_image(self, isic_id):\n        isic_id = str(isic_id)\n        image = Image.open(BytesIO(self.hdf5_file[isic_id][()]))\n        image = image.convert(\"RGB\")\n        image = np.array(image)\n        if self.feature_extractor:\n            image = self.feature_extractor(images=image, return_tensors=\"tf\").pixel_values[0]\n        return image\n\n    def _generator(self):\n        for idx in range(len(self.isic_ids)):\n            yield self._load_image(self.isic_ids[idx]), self.targets[idx]\n\n    def to_tf_dataset(self):\n        tf_dataset = tf.data.Dataset.from_generator(self._generator, \n                                                    output_signature=(tf.TensorSpec(shape=(3, 224, 224), dtype=tf.float32),\n                                                                      tf.TensorSpec(shape=(), dtype=tf.int64)))\n        tf_dataset = tf_dataset.batch(self.batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n        return tf_dataset","metadata":{"execution":{"iopub.status.busy":"2024-07-18T12:51:18.584757Z","iopub.execute_input":"2024-07-18T12:51:18.585316Z","iopub.status.idle":"2024-07-18T12:51:18.598678Z","shell.execute_reply.started":"2024-07-18T12:51:18.585284Z","shell.execute_reply":"2024-07-18T12:51:18.597744Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"\nmodel_name = 'google/vit-base-patch16-224'\nfeature_extractor = ViTFeatureExtractor.from_pretrained(model_name)\n\ntrain_dataset = ISICDataset(train_hdf5, train_isic_ids[train_indices], targets=train_targets[train_indices], feature_extractor=feature_extractor)\nval_dataset = ISICDataset(train_hdf5, train_isic_ids[val_indices], targets=train_targets[val_indices], feature_extractor=feature_extractor)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-18T12:51:18.599828Z","iopub.execute_input":"2024-07-18T12:51:18.600132Z","iopub.status.idle":"2024-07-18T12:51:18.742119Z","shell.execute_reply.started":"2024-07-18T12:51:18.600108Z","shell.execute_reply":"2024-07-18T12:51:18.741157Z"},"trusted":true},"execution_count":81,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"# Maak TensorFlow datasets\ntf_train_dataset = train_dataset.to_tf_dataset()\ntf_val_dataset = val_dataset.to_tf_dataset()","metadata":{"execution":{"iopub.status.busy":"2024-07-18T12:51:18.743342Z","iopub.execute_input":"2024-07-18T12:51:18.743632Z","iopub.status.idle":"2024-07-18T12:51:18.806277Z","shell.execute_reply.started":"2024-07-18T12:51:18.743605Z","shell.execute_reply":"2024-07-18T12:51:18.805334Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"vit_model = TFViTModel.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2024-07-18T12:51:18.807453Z","iopub.execute_input":"2024-07-18T12:51:18.807749Z","iopub.status.idle":"2024-07-18T12:51:19.977447Z","shell.execute_reply.started":"2024-07-18T12:51:18.807723Z","shell.execute_reply":"2024-07-18T12:51:19.976702Z"},"trusted":true},"execution_count":83,"outputs":[{"name":"stderr","text":"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFViTModel: ['classifier.bias', 'classifier.weight']\n- This IS expected if you are initializing TFViTModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFViTModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights or buffers of the TF 2.0 model TFViTModel were not initialized from the PyTorch model and are newly initialized: ['vit.pooler.dense.weight', 'vit.pooler.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\n\ndevice_name = tf.test.gpu_device_name()\n\nif \"GPU\" not in device_name:\n    print(\"GPU device not found\")\n    \nprint('Found GPU at: {}'.format(device_name))\n\nprint(\"GPU\", \"available (YESS!!!!)\" if tf.config.list_physical_devices(\"GPU\") else \"not available :(\")","metadata":{"execution":{"iopub.status.busy":"2024-07-18T12:51:19.978476Z","iopub.execute_input":"2024-07-18T12:51:19.978810Z","iopub.status.idle":"2024-07-18T12:51:19.986226Z","shell.execute_reply.started":"2024-07-18T12:51:19.978782Z","shell.execute_reply":"2024-07-18T12:51:19.985355Z"},"trusted":true},"execution_count":84,"outputs":[{"name":"stdout","text":"Found GPU at: /device:GPU:0\nGPU available (YESS!!!!)\n","output_type":"stream"}]},{"cell_type":"code","source":"class CustomViTModel(tf.keras.Model):\n    def __init__(self, backbone, num_classes):\n        super(CustomViTModel, self).__init__()\n        self.backbone = backbone\n        self.dense = layers.Dense(num_classes, activation='softmax')\n\n    def call(self, inputs):\n        with tf.device('/GPU:0'):\n            outputs = self.backbone(inputs).last_hidden_state[:, 0, :]\n            outputs = self.dense(outputs)\n            return outputs","metadata":{"execution":{"iopub.status.busy":"2024-07-18T12:51:19.987693Z","iopub.execute_input":"2024-07-18T12:51:19.988178Z","iopub.status.idle":"2024-07-18T12:51:19.996147Z","shell.execute_reply.started":"2024-07-18T12:51:19.988146Z","shell.execute_reply":"2024-07-18T12:51:19.995410Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"num_classes = len(np.unique(train_targets))\ncustom_vit_model = CustomViTModel(vit_model, num_classes)","metadata":{"execution":{"iopub.status.busy":"2024-07-18T12:51:19.997127Z","iopub.execute_input":"2024-07-18T12:51:19.997368Z","iopub.status.idle":"2024-07-18T12:51:20.011058Z","shell.execute_reply.started":"2024-07-18T12:51:19.997347Z","shell.execute_reply":"2024-07-18T12:51:20.010321Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"# Compileer het model met een gebruikelijke loss-functie\ncustom_vit_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n                         loss='sparse_categorical_crossentropy',\n                         metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-07-18T12:51:20.012245Z","iopub.execute_input":"2024-07-18T12:51:20.012524Z","iopub.status.idle":"2024-07-18T12:51:20.025726Z","shell.execute_reply.started":"2024-07-18T12:51:20.012499Z","shell.execute_reply":"2024-07-18T12:51:20.024877Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"history = custom_vit_model.fit(tf_train_dataset, epochs=10, validation_data=tf_val_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-07-18T12:51:20.026791Z","iopub.execute_input":"2024-07-18T12:51:20.027064Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/10\n    552/Unknown - 1062s 2s/step - loss: 0.0828 - accuracy: 0.9796WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7d82dd713eb0> and will run it as-is.\nCause: Unable to locate the source code of <function Model.make_test_function.<locals>.test_function at 0x7d82dd713eb0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n552/552 [==============================] - 1261s 2s/step - loss: 0.0828 - accuracy: 0.9796 - val_loss: 0.0622 - val_accuracy: 0.9823\nEpoch 2/10\n552/552 [==============================] - 1107s 2s/step - loss: 0.0646 - accuracy: 0.9832 - val_loss: 0.0660 - val_accuracy: 0.9823\nEpoch 3/10\n552/552 [==============================] - 1099s 2s/step - loss: 0.0535 - accuracy: 0.9860 - val_loss: 0.0808 - val_accuracy: 0.9753\nEpoch 4/10\n 89/552 [===>..........................] - ETA: 12:54 - loss: 0.0608 - accuracy: 0.9863","output_type":"stream"}]},{"cell_type":"code","source":"# Genereer voorspellingen op de testset\ntest_images = []\ntest_labels = []\nfor batch in tf_val_dataset:\n    images, labels = batch\n    test_images.append(images)\n    test_labels.append(labels)\n\ntest_images = tf.concat(test_images, axis=0)\ntest_labels = tf.concat(test_labels, axis=0)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-18T12:47:37.341098Z","iopub.status.idle":"2024-07-18T12:47:37.341619Z","shell.execute_reply.started":"2024-07-18T12:47:37.341375Z","shell.execute_reply":"2024-07-18T12:47:37.341396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Verkrijg de voorspellingen van het model\npredictions = custom_vit_model.predict(test_images)\npredicted_probabilities = tf.reduce_max(predictions, axis=1)\n\n# Binarize de test labels voor ROC berekening\ntest_labels_binary = (test_labels == 1).numpy().astype(int)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-18T12:47:37.343131Z","iopub.status.idle":"2024-07-18T12:47:37.343588Z","shell.execute_reply.started":"2024-07-18T12:47:37.343350Z","shell.execute_reply":"2024-07-18T12:47:37.343369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Bereken de ROC-curve en de pAUC\nfpr, tpr, thresholds = roc_curve(test_labels_binary, predicted_probabilities)\npartial_auc = auc(fpr, tpr)\n\nprint(f'Partial AUC: {partial_auc}')","metadata":{"execution":{"iopub.status.busy":"2024-07-18T12:47:37.345231Z","iopub.status.idle":"2024-07-18T12:47:37.345551Z","shell.execute_reply.started":"2024-07-18T12:47:37.345391Z","shell.execute_reply":"2024-07-18T12:47:37.345404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# class CustomViTModel(tf.keras.Model):\n#     def __init__(self, backbone, num_classes):\n#         super(CustomViTModel, self).__init__()\n#         self.backbone = backbone\n#         self.dense = layers.Dense(num_classes, activation='softmax')\n\n#     def call(self, inputs):\n#         outputs = self.backbone(inputs).last_hidden_state[:, 0, :]\n#         outputs = self.dense(outputs)\n#         return outputs","metadata":{"execution":{"iopub.status.busy":"2024-07-18T12:47:37.346764Z","iopub.status.idle":"2024-07-18T12:47:37.347123Z","shell.execute_reply.started":"2024-07-18T12:47:37.346946Z","shell.execute_reply":"2024-07-18T12:47:37.346966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Definieer de EmbeddingClassifierModel class\n# class EmbeddingClassifierModel:\n#     \"\"\"\n#     Wrapper model that creates a classification model out of an embedding\n#     model and a reference dataset.\n#     \"\"\"\n\n#     def __init__(self,\n#                  model: CustomViTModel,\n#                  reference_embeddings: np.ndarray,\n#                  reference_labels: np.ndarray,\n#                  distance_metric: str = 'euclidean'):\n#         \"\"\"\n#         Initialize the model.\n#         \"\"\"\n#         self.model = model\n#         self.reference_embeddings = reference_embeddings\n#         self.reference_labels = reference_labels\n#         self.distance_metric = distance_metric\n#         self.labels = np.unique(reference_labels)\n\n#     def predict(self, image: Image) -> Mapping[str, float]:\n#         image_embedding = self.model.predict(image[np.newaxis, ...])\n#         return self._get_classification_scores(image_embedding)\n\n#     def _get_classification_scores(self, image_embedding: np.ndarray) -> Mapping[str, float]:\n#         \"\"\"\n#         Calculate the classification scores for one image embedding.\n#         \"\"\"\n#         distances = cdist(image_embedding, self.reference_embeddings, metric=self.distance_metric)\n#         classification = {}\n#         for label in self.labels:\n#             label_distances = distances[:, self.reference_labels == label]\n#             classification[label] = np.mean(label_distances)\n#         return classification\n","metadata":{"execution":{"iopub.status.busy":"2024-07-18T12:47:37.348595Z","iopub.status.idle":"2024-07-18T12:47:37.348909Z","shell.execute_reply.started":"2024-07-18T12:47:37.348754Z","shell.execute_reply":"2024-07-18T12:47:37.348767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# # Gebruik de EmbeddingClassifierModel\n# reference_embeddings = train_embeddings.numpy()  # Use the generated embeddings\n# reference_labels = train_targets[train_indices]  # Use the training labels\n\n# classifier = EmbeddingClassifierModel(custom_vit_model, reference_embeddings, reference_labels)\n\n# # Voorbeeld classificatie\n# test_image_id = test_isic_ids[0]\n# test_image = Image.open(BytesIO(test_hdf5[test_image_id][()])).convert(\"RGB\")\n# test_image = feature_extractor(images=np.array(test_image), return_tensors=\"tf\").pixel_values[0]\n\n# classification_scores = classifier.predict(test_image)\n# print(\"Classification Scores:\", classification_scores)","metadata":{"execution":{"iopub.status.busy":"2024-07-18T12:47:37.349896Z","iopub.status.idle":"2024-07-18T12:47:37.350262Z","shell.execute_reply.started":"2024-07-18T12:47:37.350092Z","shell.execute_reply":"2024-07-18T12:47:37.350106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}